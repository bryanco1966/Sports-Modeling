{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datatools import DataGrapher\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the data\n",
    "\n",
    "nba = pd.read_csv('./data/nba_analysis_data.csv')\n",
    "nba.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate test from train\n",
    "\n",
    "nba_train = nba[nba.test == 0]\n",
    "nba_test = nba[nba.test ==1]  #scott tarlow scotttarlow@gmail.com\n",
    "#learn a domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_train = nba_train[nba_train.playoff_game == 1]\n",
    "nba_test = nba_test[nba_test.playoff_game == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = nba_train.drop(columns = ['cover','home_win_margin', \n",
    "                        'date', 'dataset','line_cv', \n",
    "                        'home_starter5', 'teams', 'away_team',\n",
    "                        'away_starter2', 'away_starter3',\n",
    "                        'away_starter4', 'away_starter5',\n",
    "                        'ref_1', 'ref_3', 'crew_referees',\n",
    "                        'away_pace', 'away_spread',\n",
    "                        'away_line_cv',  'away_cover',\n",
    "                        'home_payout', 'away_payout', 'over', 'under',\n",
    "                        'total_score', 'total_diff'         ])\n",
    "\n",
    "\n",
    "#X = nba[features]\n",
    "y_train = nba_train['cover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= nba_test.drop(columns = ['cover','home_win_margin', \n",
    "                        'date', 'dataset','line_cv', \n",
    "                        'home_starter5', 'teams', 'away_team',\n",
    "                        'away_starter2', 'away_starter3',\n",
    "                        'away_starter4', 'away_starter5',\n",
    "                        'ref_1', 'ref_3', 'crew_referees',\n",
    "                        'away_pace', 'away_spread',\n",
    "                        'away_line_cv',  'away_cover',\n",
    "                        'home_payout', 'away_payout', 'over', 'under',\n",
    "                        'total_score', 'total_diff'       ])\n",
    "\n",
    "y_test = nba_test.away_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 148)"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711, 148)"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Terms\n",
    "\n",
    "At one point in the modeling process I hoped to get better results by including some interactions in the model.  They did not appear significant and added noise so they were removed, but I left the code in case I wanted to reinsert them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #create interactions  tested but did not help the model\n",
    "# poly = PolynomialFeatures(degree = 2, interaction_only= True)\n",
    "# X_poly = poly.fit_transform(X_train)\n",
    "# X_poly_test = poly.transform(X_test)\n",
    "# X_poly = pd.DataFrame(X_poly, \n",
    "#                       columns = poly.get_feature_names(X_train.columns))\n",
    "# X_poly_test = pd.DataFrame(X_poly_test, \n",
    "#                            columns = poly.get_feature_names(X_test.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and Transform the data\n",
    "\n",
    "I use standard scaler scale the data and then do a principal components analysis to transform the data.  I do not care about inference in this case only prediction and there is a good deal of correlation between variables. So I decided to transform the data to reduce the number and get orthoginal features without losing much information.  I retain 99% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#scaling data to use in various other methods\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(n_components=75)\n",
    "X_train_pc = pc.fit_transform(X_train_scaled)\n",
    "X_test_pc = pc.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:             [0.11694139 0.10466322 0.06263363 0.04348807 0.04020162 0.03739641\n",
      " 0.03465436 0.03171007 0.03088486 0.02746436 0.0268335  0.02449559\n",
      " 0.02349233 0.01981358 0.0187899  0.01781639 0.01615334 0.01557077\n",
      " 0.01526551 0.01447885 0.01406536 0.01263087 0.01230269 0.01185432\n",
      " 0.01148084 0.01019796 0.01010359 0.00978173 0.00931831 0.00867519\n",
      " 0.00824706 0.00784966 0.00771266 0.00722275 0.00688001 0.00657454\n",
      " 0.00636737 0.00601614 0.00578821 0.00543573 0.00496192 0.00474887\n",
      " 0.00467484 0.0045144  0.00415594 0.00392611 0.00377081 0.0036287\n",
      " 0.00338606 0.00335798 0.00319686 0.00307144 0.00295852 0.00272001\n",
      " 0.00264951 0.00254457 0.00240447 0.0023217  0.00207763 0.00197976\n",
      " 0.0019091  0.00185138 0.0018229  0.00167725 0.00158737 0.00148908\n",
      " 0.00139441 0.00136833 0.00132082 0.00125973 0.00115397 0.00110103\n",
      " 0.00104157 0.00099801 0.0009725 ]\n",
      "Cumulative explained variance:  [0.11694139 0.22160461 0.28423824 0.32772631 0.36792792 0.40532433\n",
      " 0.43997869 0.47168876 0.50257363 0.53003799 0.55687149 0.58136708\n",
      " 0.60485941 0.62467299 0.64346289 0.66127928 0.67743262 0.69300339\n",
      " 0.7082689  0.72274774 0.73681311 0.74944398 0.76174667 0.77360099\n",
      " 0.78508183 0.7952798  0.80538338 0.81516512 0.82448343 0.83315861\n",
      " 0.84140567 0.84925533 0.85696799 0.86419074 0.87107075 0.87764529\n",
      " 0.88401266 0.8900288  0.89581701 0.90125274 0.90621466 0.91096353\n",
      " 0.91563837 0.92015277 0.92430872 0.92823483 0.93200564 0.93563434\n",
      " 0.9390204  0.94237837 0.94557523 0.94864667 0.9516052  0.95432521\n",
      " 0.95697472 0.95951929 0.96192376 0.96424546 0.96632309 0.96830285\n",
      " 0.97021195 0.97206333 0.97388623 0.97556348 0.97715084 0.97863992\n",
      " 0.98003434 0.98140266 0.98272348 0.98398321 0.98513719 0.98623821\n",
      " 0.98727978 0.98827779 0.98925029]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pc.explained_variance_ratio_\n",
    "print('Explained variance:            ', var_exp)\n",
    "\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative explained variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "The first model I tested out was the logistic regression on good thing about the NBA data is that much of the data seemed to be normally distributed and my transformed features are uncorrelated so I thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6469760900140648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(Cs = [1000],\n",
    "                         max_iter=1000,\n",
    "                         penalty = 'l1',\n",
    "                         tol = .00001,\n",
    "                         solver ='saga' )\n",
    "\n",
    "\n",
    "lr.fit(X_train_pc, y_train)\n",
    "print(lr.score(X_train_pc, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_pc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lr   = lr.predict(X_train_pc)\n",
    "y_hat_lrp  = lr.predict_proba(X_train_pc)\n",
    "y_hat_lrt  = lr.predict(X_test_pc)\n",
    "y_hat_lrtp = lr.predict_proba(X_test_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       333\n",
      "           1       0.66      0.69      0.68       378\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       711\n",
      "   macro avg       0.65      0.64      0.64       711\n",
      "weighted avg       0.65      0.65      0.65       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_hat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.66      0.59        73\n",
      "           1       0.59      0.47      0.52        77\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       150\n",
      "   macro avg       0.56      0.56      0.56       150\n",
      "weighted avg       0.57      0.56      0.56       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_lrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199, 134],\n",
       "       [117, 261]])"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_train, y_hat_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 25],\n",
       "       [41, 36]])"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_lrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "The second model I tested is the Support Vector Machine Model I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)\n",
    "svc_params = {\n",
    "    'kernel' : ['linear'  ], \n",
    "    'C'      : [.05, .15, .1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5690647664978252\n",
      "{'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(svc, \n",
    "                  param_grid=svc_params, \n",
    "                  scoring='precision', \n",
    "                  cv = 5)\n",
    "gs.fit(X_train_pc, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967741935483871"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_pc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict categories and  probabilities for svc model\n",
    "\n",
    "y_hat_svc   = gs.predict(X_train_pc)\n",
    "y_hat_svcp  = gs.predict_proba(X_train_pc)\n",
    "y_hat_svct  = gs.predict(X_test_pc)\n",
    "y_hat_svctp = gs.predict_proba(X_test_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       333\n",
      "           1       0.67      0.72      0.69       378\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       711\n",
      "   macro avg       0.66      0.66      0.66       711\n",
      "weighted avg       0.66      0.66      0.66       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_hat_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60        73\n",
      "           1       0.60      0.48      0.53        77\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       150\n",
      "   macro avg       0.57      0.57      0.56       150\n",
      "weighted avg       0.57      0.57      0.56       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_svct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196, 137],\n",
       "       [105, 273]])"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_train, y_hat_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 25],\n",
       "       [40, 37]])"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_svct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "I also wanted to try fitting a neural network.  I do not care about the inference implications, but I found that the neural network had to much variance depending on starting weights so I decided not to use it in predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, \n",
    "                activation = 'relu',\n",
    "                input_dim = X_train_pc.shape[1],\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.85))\n",
    "\n",
    "#model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid')) #output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711 samples, validate on 150 samples\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 1s 1ms/step - loss: 1.9175 - acc: 0.5288 - val_loss: 1.6052 - val_acc: 0.4200\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.8523 - acc: 0.5359 - val_loss: 1.5626 - val_acc: 0.4267\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.9105 - acc: 0.5246 - val_loss: 1.5208 - val_acc: 0.4333\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 0s 22us/step - loss: 1.8438 - acc: 0.5232 - val_loss: 1.4808 - val_acc: 0.4267\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 0s 21us/step - loss: 1.7601 - acc: 0.5260 - val_loss: 1.4473 - val_acc: 0.4267\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 0s 20us/step - loss: 1.7733 - acc: 0.5007 - val_loss: 1.4158 - val_acc: 0.4467\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 0s 19us/step - loss: 1.5830 - acc: 0.5387 - val_loss: 1.3895 - val_acc: 0.4667\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 0s 21us/step - loss: 1.6814 - acc: 0.5204 - val_loss: 1.3634 - val_acc: 0.4600\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 0s 27us/step - loss: 1.6087 - acc: 0.5035 - val_loss: 1.3380 - val_acc: 0.4667\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 0s 20us/step - loss: 1.5664 - acc: 0.5091 - val_loss: 1.3141 - val_acc: 0.4800\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 0s 21us/step - loss: 1.5901 - acc: 0.5204 - val_loss: 1.2913 - val_acc: 0.4933\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 0s 19us/step - loss: 1.4698 - acc: 0.4937 - val_loss: 1.2712 - val_acc: 0.4867\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 0s 23us/step - loss: 1.4446 - acc: 0.5218 - val_loss: 1.2527 - val_acc: 0.4667\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 0s 28us/step - loss: 1.4323 - acc: 0.5021 - val_loss: 1.2325 - val_acc: 0.4667\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 0s 22us/step - loss: 1.4484 - acc: 0.5049 - val_loss: 1.2119 - val_acc: 0.4667\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.4323 - acc: 0.5035 - val_loss: 1.1920 - val_acc: 0.4600\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.2999 - acc: 0.5260 - val_loss: 1.1733 - val_acc: 0.4667\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 0s 21us/step - loss: 1.2938 - acc: 0.5120 - val_loss: 1.1562 - val_acc: 0.4600\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 0s 29us/step - loss: 1.2669 - acc: 0.5134 - val_loss: 1.1401 - val_acc: 0.4533\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 0s 20us/step - loss: 1.2549 - acc: 0.5035 - val_loss: 1.1252 - val_acc: 0.4467\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 0s 17us/step - loss: 1.2269 - acc: 0.5190 - val_loss: 1.1113 - val_acc: 0.4533\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.1874 - acc: 0.5105 - val_loss: 1.0985 - val_acc: 0.4600\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.1474 - acc: 0.5316 - val_loss: 1.0855 - val_acc: 0.4600\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 0s 22us/step - loss: 1.0927 - acc: 0.5738 - val_loss: 1.0734 - val_acc: 0.4533\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 0s 22us/step - loss: 1.1321 - acc: 0.5387 - val_loss: 1.0610 - val_acc: 0.4600\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 0s 19us/step - loss: 1.1234 - acc: 0.5021 - val_loss: 1.0485 - val_acc: 0.4667\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.0672 - acc: 0.5584 - val_loss: 1.0361 - val_acc: 0.4667\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 0s 18us/step - loss: 1.0931 - acc: 0.5443 - val_loss: 1.0246 - val_acc: 0.4667\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 0s 17us/step - loss: 1.0097 - acc: 0.5851 - val_loss: 1.0131 - val_acc: 0.4467\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 0s 21us/step - loss: 1.0492 - acc: 0.5457 - val_loss: 1.0030 - val_acc: 0.4467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3a399588>"
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X_train_pc, \n",
    "          y_train, epochs =30, \n",
    "          batch_size= 128, \n",
    "          validation_data=(X_test_pc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a probability\n",
    "\n",
    "y_hat_nnp = model.predict(X_train_pc)\n",
    "y_hat_nntp = model.predict(X_test_pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357732351484347\n",
      "{'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 120, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_params = {'n_estimators'      : [200],\n",
    "             'max_depth'         : [3],\n",
    "             'min_samples_split' : [120],\n",
    "             'min_samples_leaf'  : [10] }\n",
    "\n",
    "gs1 = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  scoring='precision',\n",
    "                 cv =5)\n",
    "gs1.fit(X_train_pc, y_train)\n",
    "print(gs1.best_score_)\n",
    "print(gs1.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5546875"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_test_pc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_rf   = gs1.predict(X_train_pc)\n",
    "y_hat_rfp  = gs1.predict_proba(X_train_pc)\n",
    "y_hat_rft  = gs1.predict(X_test_pc)\n",
    "y_hat_rftp = gs1.predict_proba(X_test_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.39      0.55       333\n",
      "           1       0.65      0.98      0.78       378\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       711\n",
      "   macro avg       0.80      0.69      0.67       711\n",
      "weighted avg       0.79      0.71      0.67       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_hat_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.22      0.34        73\n",
      "           1       0.55      0.92      0.69        77\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       150\n",
      "   macro avg       0.64      0.57      0.51       150\n",
      "weighted avg       0.64      0.58      0.52       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_rft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 203],\n",
       "       [  6, 372]])"
      ]
     },
     "execution_count": 1066,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_train, y_hat_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 57],\n",
       "       [ 6, 71]])"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_rft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying train and testing data to allow for changing prob thresholds and printing the \n",
    "#roc curves \n",
    "#Random Forest\n",
    "nba_train.loc[:, 'actual_y'] = y_train\n",
    "nba_train.loc[:, 'predicted_label_rf'] = y_hat_rf\n",
    "nba_train.loc[:, 'predicted_proba_rfp'] = y_hat_rfp[:, 1]\n",
    "\n",
    "#SVC\n",
    "\n",
    "nba_train.loc[:, 'predicted_label_svc'] = y_hat_svc\n",
    "nba_train.loc[:, 'predicted_proba_svcp'] = y_hat_svcp[:, 1]\n",
    "\n",
    "#Logistic\n",
    "nba_train.loc[:, 'predicted_label_lr'] = y_hat_lr\n",
    "nba_train.loc[:, 'predicted_proba_lrp'] = y_hat_lrp[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "nba_test.loc[:, 'actual_y'] = y_test\n",
    "nba_test.loc[:, 'predicted_label_rf'] = y_hat_rft\n",
    "nba_test.loc[:, 'predicted_proba_rfp'] = y_hat_rftp[:, 1]\n",
    "\n",
    "#SVC\n",
    "\n",
    "nba_test.loc[:, 'predicted_label_svc'] = y_hat_svct\n",
    "nba_test.loc[:, 'predicted_proba_svcp'] = y_hat_svctp[:,1]\n",
    "\n",
    "#Logistic\n",
    "nba_test.loc[:, 'predicted_label_lr'] = y_hat_lrt\n",
    "nba_test.loc[:, 'predicted_proba_lrp'] = y_hat_lrtp[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label_svc\n",
      "0   -9.640\n",
      "1    8.633\n",
      "Name: away_payout, dtype: float64\n",
      "predicted_label_svc\n",
      "0     1.814\n",
      "1   -14.275\n",
      "Name: home_payout, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(nba_test.groupby(['predicted_label_svc'])['away_payout'].sum())\n",
    "print(nba_test.groupby(['predicted_label_svc'])['home_payout'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label_lr\n",
      "0   -9.731\n",
      "1    8.724\n",
      "Name: away_payout, dtype: float64\n",
      "predicted_label_lr\n",
      "0     1.723\n",
      "1   -14.184\n",
      "Name: home_payout, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(nba_test.groupby(['predicted_label_lr'])['away_payout'].sum())\n",
    "print(nba_test.groupby(['predicted_label_lr'])['home_payout'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label_rf\n",
      "0   -10.546\n",
      "1     9.539\n",
      "Name: away_payout, dtype: float64\n",
      "predicted_label_rf\n",
      "0     8.544\n",
      "1   -21.005\n",
      "Name: home_payout, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(nba_test.groupby(['predicted_label_rf'])['away_payout'].sum())\n",
    "print(nba_test.groupby(['predicted_label_rf'])['home_payout'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, nba_test['predicted_proba_lrp'])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1, tpr1, _ = roc_curve(y_test, nba_test['predicted_proba_svcp'])\n",
    "roc_auc1 = auc(fpr1, tpr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr2, tpr2, _ = roc_curve(y_test, nba_test['predicted_proba_rfp'])\n",
    "roc_auc2 = auc(fpr2, tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a387c7ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot \n",
    "plt.figure(figsize = (12,7))\n",
    "line_width = 3\n",
    "\n",
    "plt.plot(fpr, tpr, lw = line_width, color=\"darkorange\", \n",
    "         label = \"Log Reg ROC Curve %.2f\" % roc_auc)\n",
    "plt.plot(fpr1, tpr1, lw = line_width, color=\"red\", \n",
    "         label = \"SVC ROC Curve %.2f\" % roc_auc1)\n",
    "plt.plot(fpr2, tpr2, lw = line_width, color=\"yellow\", \n",
    "         label = \"Random Forest ROC Curve %.2f\" % roc_auc2)\n",
    "plt.plot([0,1], [0, 1], lw = line_width, linestyle=\"--\", color=\"navy\")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve on Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Logistic Regression :0.42\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -8.730\n",
      "1    7.723\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     2.724\n",
      "1   -15.185\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.43\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -9.821\n",
      "1    8.814\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     3.542\n",
      "1   -16.003\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.44\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -11.821\n",
      "1    10.814\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     5.360\n",
      "1   -17.821\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.45\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -10.912\n",
      "1     9.905\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     4.360\n",
      "1   -16.821\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.46\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -9.094\n",
      "1    8.087\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     2.360\n",
      "1   -14.821\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.47\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -7.458\n",
      "1    6.451\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     0.178\n",
      "1   -12.639\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.48\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -10.549\n",
      "1     9.542\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     2.814\n",
      "1   -15.275\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.49\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -9.640\n",
      "1    8.633\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     1.814\n",
      "1   -14.275\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.5\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -9.731\n",
      "1    8.724\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0     1.723\n",
      "1   -14.184\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.51\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -6.095\n",
      "1    5.088\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0    -2.277\n",
      "1   -10.184\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.52\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -5.186\n",
      "1    4.179\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0   -3.277\n",
      "1   -9.184\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.53\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -6.277\n",
      "1    5.270\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0    -2.459\n",
      "1   -10.002\n",
      "Name: home_payout, dtype: float64\n",
      " \n",
      "Test Logistic Regression :0.54\n",
      "Return of Away Games:  predicted_label_lr\n",
      "0   -8.277\n",
      "1    7.270\n",
      "Name: away_payout, dtype: float64\n",
      "Return of Home Games:  predicted_label_lr\n",
      "0    -0.641\n",
      "1   -11.820\n",
      "Name: home_payout, dtype: float64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for prob in range(42, 55, 1):\n",
    "    proba = prob/100\n",
    "    \n",
    "    nba_test.loc[:, 'predicted_label_lr']= nba_test['predicted_proba_lrp'].map(\n",
    "        lambda p: 1 if p > proba else 0)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    print('Test Logistic Regression :' + str(proba))\n",
    "\n",
    "    print (\"Return of Away Games: \", nba_test.groupby(\n",
    "        \"predicted_label_lr\").away_payout.sum())\n",
    "    print (\"Return of Home Games: \", nba_test.groupby(\n",
    "        \"predicted_label_lr\").home_payout.sum())\n",
    "    \n",
    "    print (\" \")\n",
    "   \n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Analysis\n",
    "\n",
    "For the Logisitic Regession Analysis .44 seems to consistently rank a the best threshold.  Therefore, I change the classification to .44.  W\n",
    "\n",
    "I conducted a Threshold Analysis to determine if I should set the probability Threshold at a value other than .5.  The Roc curve does not show any enormous jumps in precision.  Running the model a number of times.  The maximum precision is usually between .48 and .52 but is not consistent across models. \n",
    "\n",
    "Therefore, I am leaving the break point at .5 since that point consistently show a profitable break.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nba_test.loc[:, 'predicted_label_lr']= nba_test['predicted_proba_lrp'].map(\n",
    "    lambda p: 1 if p > .44 else 0)\n",
    "    \n",
    "    nba_test.loc[:, 'predicted_label_svc']= nba_test.predicted_proba_svcp.map(\n",
    "    lambda p: 1 if p > .50 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.520000\n",
      "0    0.253333\n",
      "1    0.226667\n",
      "Name: vote, dtype: float64\n",
      "vote\n",
      "0    -1.729\n",
      "1   -10.092\n",
      "2    10.814\n",
      "Name: away_payout, dtype: float64\n",
      "vote\n",
      "0    -1.729\n",
      "1     7.089\n",
      "2   -17.821\n",
      "Name: home_payout, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "nba_test['vote']= (nba_test.predicted_label_svc + \n",
    "                   nba_test.predicted_label_lr)\n",
    "\n",
    "print(nba_test.vote.value_counts(normalize = True))\n",
    "print(nba_test.groupby(['vote'])['away_payout'].sum())\n",
    "print(nba_test.groupby(['vote'])['home_payout'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined \n",
    "nba_test['vote_with_rf'] = (nba_test.predicted_label_svc + \n",
    "                            nba_test.predicted_label_lr +\n",
    "                            nba_test.predicted_label_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.506667\n",
       "2    0.200000\n",
       "1    0.200000\n",
       "0    0.093333\n",
       "Name: vote_with_rf, dtype: float64"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_test.vote_with_rf.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote_with_rf\n",
       "0    -8.273\n",
       "1     4.362\n",
       "2    -8.001\n",
       "3    10.905\n",
       "Name: away_payout, dtype: float64"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_test.groupby(['vote_with_rf'])['away_payout'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote_with_rf\n",
       "0     6.999\n",
       "1    -7.092\n",
       "2     5.362\n",
       "3   -17.730\n",
       "Name: home_payout, dtype: float64"
      ]
     },
     "execution_count": 1085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_test.groupby(['vote_with_rf'])['home_payout'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10206    1\n",
      "10207    1\n",
      "10208    1\n",
      "10242    1\n",
      "10243    0\n",
      "10244    1\n",
      "10245    0\n",
      "10246    0\n",
      "10247    0\n",
      "10248    0\n",
      "Name: predicted_label_svc, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predicted_label_svc\n",
       "0    0.487372\n",
       "1    0.532259\n",
       "Name: predicted_proba_svcp, dtype: float64"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nba_test.predicted_label_svc.head(10))\n",
    "nba_test.groupby(['predicted_label_svc'])['predicted_proba_svcp'].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "\n",
    "I added a section with the Random Forest Estimator included in the ensemble prediction.  It generally predicts better than the two model ensemble, but includes more variance.  The two model ensemble classifier is consistently positive with both models agreeing betting the away team and if not betting the home team. \n",
    "\n",
    "If you include the Random Forest.  The best predictions are betting the away team if all three models predict the away team else bet the home team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>date</th>\n",
       "      <th>teams</th>\n",
       "      <th>home_starter5</th>\n",
       "      <th>crew_referees</th>\n",
       "      <th>spread</th>\n",
       "      <th>total</th>\n",
       "      <th>moneyline</th>\n",
       "      <th>away_team</th>\n",
       "      <th>away_pace</th>\n",
       "      <th>...</th>\n",
       "      <th>in_conference_game</th>\n",
       "      <th>actual_y</th>\n",
       "      <th>predicted_label_rf</th>\n",
       "      <th>predicted_proba_rfp</th>\n",
       "      <th>predicted_label_svc</th>\n",
       "      <th>predicted_proba_svcp</th>\n",
       "      <th>predicted_label_lr</th>\n",
       "      <th>predicted_proba_lrp</th>\n",
       "      <th>vote</th>\n",
       "      <th>vote_with_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-16</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>Zach Zarba</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>100.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508624</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397912</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>David Guthrie</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>98.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384416</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>James Williams</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-280.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>93.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515357</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667802</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Jerian Grant</td>\n",
       "      <td>Brian Forte</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>207.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596870</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10243</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Jerian Grant</td>\n",
       "      <td>Eric Lewis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Isaiah Canaan</td>\n",
       "      <td>James Williams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>90.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524604</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471110</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10245</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>Tony Brown</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>96.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>Ron Garretson</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>99.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472905</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10247</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>216.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>90.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10248</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>David Guthrie</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>90.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305897</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>Pat Fraher</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-2500.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>90.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565359</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340284</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-16</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>Kane Fitzgerald</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>205.5</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>94.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582380</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>-340.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>92.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>Ed Malloy</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>92.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427651</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>Tony Brown</td>\n",
       "      <td>3.5</td>\n",
       "      <td>211.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>96.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671290</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>David Guthrie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>211.5</td>\n",
       "      <td>155.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>97.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>Kane Fitzgerald</td>\n",
       "      <td>2.0</td>\n",
       "      <td>214.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>95.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>Pat Fraher</td>\n",
       "      <td>5.5</td>\n",
       "      <td>214.5</td>\n",
       "      <td>245.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>92.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736269</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>3.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>91.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677631</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>Ron Garretson</td>\n",
       "      <td>5.5</td>\n",
       "      <td>219.5</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>98.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583389</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>Kane Fitzgerald</td>\n",
       "      <td>9.0</td>\n",
       "      <td>214.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>98.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535271</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488018</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>Zach Zarba</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>225.5</td>\n",
       "      <td>-355.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>99.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-06-04</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>Scott Foster</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>221.5</td>\n",
       "      <td>-425.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>106.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533924</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>Ed Malloy</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>230.5</td>\n",
       "      <td>-400.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>99.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>Zach Zarba</td>\n",
       "      <td>6.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475317</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>Sean Wright</td>\n",
       "      <td>6.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>99.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502226</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336394</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Ed Malloy</td>\n",
       "      <td>5.5</td>\n",
       "      <td>209.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>92.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464295</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>James Williams</td>\n",
       "      <td>8.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542216</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463341</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>San_Antonio</td>\n",
       "      <td>Patty Mills</td>\n",
       "      <td>Bill Kennedy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>103.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543570</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>2017 Playoffs</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>San_Antonio</td>\n",
       "      <td>Patty Mills</td>\n",
       "      <td>Zach Zarba</td>\n",
       "      <td>9.5</td>\n",
       "      <td>216.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>106.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511447</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392111</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Terry Rozier</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521740</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380716</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11757</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>James Williams</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>217.0</td>\n",
       "      <td>-1300.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>93.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540627</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781375</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11758</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>Mark Lindsay</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>-800.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>97.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437741</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11759</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>Brian Forte</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-1200.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541623</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418273</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11791</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>Mark Lindsay</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11792</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>212.5</td>\n",
       "      <td>-295.0</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>95.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535566</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>Bill Kennedy</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>222.5</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>104.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11794</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>Sean Wright</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>227.0</td>\n",
       "      <td>-800.0</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>110.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468963</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11795</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>Josh Tiven</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-1095.0</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>104.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>Tony Brown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>98.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-21</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>Kevin Scott</td>\n",
       "      <td>3.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>107.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492327</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Terry Rozier</td>\n",
       "      <td>Derrick Collins</td>\n",
       "      <td>2.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>96.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11897</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Terry Rozier</td>\n",
       "      <td>Tony Brown</td>\n",
       "      <td>3.5</td>\n",
       "      <td>207.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>93.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11898</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Terry Rozier</td>\n",
       "      <td>Zach Zarba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>204.5</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>98.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464562</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>Jason Phillips</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>101.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-21</td>\n",
       "      <td>New_Orleans</td>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>Mark Ayotte</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>100.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.683876</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12032</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>Kane Fitzgerald</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-365.0</td>\n",
       "      <td>San_Antonio</td>\n",
       "      <td>96.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659992</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12033</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>Brent Barnaky</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>207.0</td>\n",
       "      <td>-530.0</td>\n",
       "      <td>San_Antonio</td>\n",
       "      <td>94.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526028</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474891</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12034</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Golden_State</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>Jason Phillips</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>204.5</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>San_Antonio</td>\n",
       "      <td>93.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624887</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>James Williams</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>98.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>Josh Tiven</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.5</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258052</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12070</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>Washington</td>\n",
       "      <td>John Wall</td>\n",
       "      <td>Bennie Adams</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>87.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287588</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>George Hill</td>\n",
       "      <td>Courtney Kirkland</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>91.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468304</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12072</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>George Hill</td>\n",
       "      <td>David Guthrie</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>213.0</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>93.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361402</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12106</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>Courtney Kirkland</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>-1100.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>96.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439323</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12107</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>Rodney Mott</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-900.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>103.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365968</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>Eric Lewis</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>209.5</td>\n",
       "      <td>-1150.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>91.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543055</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>Pat Fraher</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>-380.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384253</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>Courtney Kirkland</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-325.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>102.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499475</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>2018 Playoffs</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>John Goble</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>214.5</td>\n",
       "      <td>-320.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>97.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset        date         teams   home_starter5  \\\n",
       "10206  2017 Playoffs  2017-04-16    Washington       John Wall   \n",
       "10207  2017 Playoffs  2017-04-19    Washington       John Wall   \n",
       "10208  2017 Playoffs  2017-04-26    Washington       John Wall   \n",
       "10242  2017 Playoffs  2017-04-21       Chicago    Jerian Grant   \n",
       "10243  2017 Playoffs  2017-04-23       Chicago    Jerian Grant   \n",
       "10244  2017 Playoffs  2017-04-28       Chicago   Isaiah Canaan   \n",
       "10245  2017 Playoffs  2017-05-04    Washington       John Wall   \n",
       "10246  2017 Playoffs  2017-05-07    Washington       John Wall   \n",
       "10247  2017 Playoffs  2017-05-12    Washington       John Wall   \n",
       "10248  2017 Playoffs  2017-05-21     Cleveland    Kyrie Irving   \n",
       "10249  2017 Playoffs  2017-05-23     Cleveland    Kyrie Irving   \n",
       "10315  2017 Playoffs  2017-04-16        Boston   Isaiah Thomas   \n",
       "10316  2017 Playoffs  2017-04-18        Boston   Isaiah Thomas   \n",
       "10317  2017 Playoffs  2017-04-26        Boston   Isaiah Thomas   \n",
       "10352  2017 Playoffs  2017-04-20       Indiana     Jeff Teague   \n",
       "10353  2017 Playoffs  2017-04-23       Indiana     Jeff Teague   \n",
       "10354  2017 Playoffs  2017-05-05       Toronto     Cory Joseph   \n",
       "10355  2017 Playoffs  2017-05-07       Toronto     Cory Joseph   \n",
       "10356  2017 Playoffs  2017-05-17        Boston   Isaiah Thomas   \n",
       "10357  2017 Playoffs  2017-05-19        Boston   Isaiah Thomas   \n",
       "10358  2017 Playoffs  2017-05-25        Boston    Marcus Smart   \n",
       "10359  2017 Playoffs  2017-06-01  Golden_State   Stephen Curry   \n",
       "10360  2017 Playoffs  2017-06-04  Golden_State   Stephen Curry   \n",
       "10361  2017 Playoffs  2017-06-12  Golden_State   Stephen Curry   \n",
       "10493  2017 Playoffs  2017-04-22      Portland  Damian Lillard   \n",
       "10494  2017 Playoffs  2017-04-24      Portland  Damian Lillard   \n",
       "10495  2017 Playoffs  2017-05-06          Utah    Shelvin Mack   \n",
       "10496  2017 Playoffs  2017-05-08          Utah    Shelvin Mack   \n",
       "10497  2017 Playoffs  2017-05-20   San_Antonio     Patty Mills   \n",
       "10498  2017 Playoffs  2017-05-22   San_Antonio     Patty Mills   \n",
       "...              ...         ...           ...             ...   \n",
       "11723  2018 Playoffs  2018-04-28        Boston    Terry Rozier   \n",
       "11757  2018 Playoffs  2018-04-15       Houston      Chris Paul   \n",
       "11758  2018 Playoffs  2018-04-18       Houston      Chris Paul   \n",
       "11759  2018 Playoffs  2018-04-25       Houston      Chris Paul   \n",
       "11791  2018 Playoffs  2018-04-14      Portland  Damian Lillard   \n",
       "11792  2018 Playoffs  2018-04-17      Portland  Damian Lillard   \n",
       "11793  2018 Playoffs  2018-04-28  Golden_State  Andre Iguodala   \n",
       "11794  2018 Playoffs  2018-05-01  Golden_State  Andre Iguodala   \n",
       "11795  2018 Playoffs  2018-05-08  Golden_State   Stephen Curry   \n",
       "11894  2018 Playoffs  2018-04-19         Miami    Goran Dragic   \n",
       "11895  2018 Playoffs  2018-04-21         Miami    Goran Dragic   \n",
       "11896  2018 Playoffs  2018-04-30        Boston    Terry Rozier   \n",
       "11897  2018 Playoffs  2018-05-03        Boston    Terry Rozier   \n",
       "11898  2018 Playoffs  2018-05-09        Boston    Terry Rozier   \n",
       "11966  2018 Playoffs  2018-04-19   New_Orleans     Rajon Rondo   \n",
       "11967  2018 Playoffs  2018-04-21   New_Orleans     Rajon Rondo   \n",
       "12032  2018 Playoffs  2018-04-14  Golden_State  Andre Iguodala   \n",
       "12033  2018 Playoffs  2018-04-16  Golden_State  Andre Iguodala   \n",
       "12034  2018 Playoffs  2018-04-24  Golden_State  Andre Iguodala   \n",
       "12068  2018 Playoffs  2018-04-20    Washington       John Wall   \n",
       "12069  2018 Playoffs  2018-04-22    Washington       John Wall   \n",
       "12070  2018 Playoffs  2018-04-27    Washington       John Wall   \n",
       "12071  2018 Playoffs  2018-05-05     Cleveland     George Hill   \n",
       "12072  2018 Playoffs  2018-05-07     Cleveland     George Hill   \n",
       "12106  2018 Playoffs  2018-04-29       Houston      Chris Paul   \n",
       "12107  2018 Playoffs  2018-05-02       Houston      Chris Paul   \n",
       "12108  2018 Playoffs  2018-05-08       Houston      Chris Paul   \n",
       "12142  2018 Playoffs  2018-04-14       Toronto      Kyle Lowry   \n",
       "12143  2018 Playoffs  2018-04-17       Toronto      Kyle Lowry   \n",
       "12144  2018 Playoffs  2018-04-25       Toronto      Kyle Lowry   \n",
       "\n",
       "           crew_referees  spread  total  moneyline     away_team  away_pace  \\\n",
       "10206         Zach Zarba    -5.0  210.0     -240.0       Atlanta      100.2   \n",
       "10207      David Guthrie    -5.5  212.0     -250.0       Atlanta       98.6   \n",
       "10208     James Williams    -5.5  212.0     -280.0       Atlanta       93.5   \n",
       "10242        Brian Forte    -1.5  207.0      115.0        Boston       92.0   \n",
       "10243         Eric Lewis     2.0  204.0      100.0        Boston       90.0   \n",
       "10244     James Williams     0.0  204.0      135.0        Boston       90.1   \n",
       "10245         Tony Brown    -5.0  219.5     -250.0        Boston       96.4   \n",
       "10246      Ron Garretson    -4.5  215.0     -200.0        Boston       99.1   \n",
       "10247         John Goble    -5.5  216.5     -215.0        Boston       90.6   \n",
       "10248      David Guthrie    -5.5  220.0    -4000.0        Boston       90.4   \n",
       "10249         Pat Fraher   -15.0  216.0    -2500.0        Boston       90.8   \n",
       "10315    Kane Fitzgerald    -7.5  205.5     -300.0       Chicago       94.8   \n",
       "10316         John Goble    -7.0  207.0     -340.0       Chicago       92.9   \n",
       "10317          Ed Malloy    -8.0  202.0     -375.0       Chicago       92.4   \n",
       "10352         Tony Brown     3.5  211.5      100.0     Cleveland       96.3   \n",
       "10353      David Guthrie     3.0  211.5      155.0     Cleveland       97.6   \n",
       "10354    Kane Fitzgerald     2.0  214.5      135.0     Cleveland       95.9   \n",
       "10355         Pat Fraher     5.5  214.5      245.0     Cleveland       92.9   \n",
       "10356         John Goble     3.0  219.5      160.0     Cleveland       91.9   \n",
       "10357      Ron Garretson     5.5  219.5      184.0     Cleveland       98.6   \n",
       "10358    Kane Fitzgerald     9.0  214.5      431.0     Cleveland       98.7   \n",
       "10359         Zach Zarba    -7.0  225.5     -355.0     Cleveland       99.5   \n",
       "10360       Scott Foster    -8.0  221.5     -425.0     Cleveland      106.4   \n",
       "10361          Ed Malloy    -8.5  230.5     -400.0     Cleveland       99.3   \n",
       "10493         Zach Zarba     6.5  219.0      172.0  Golden_State      104.5   \n",
       "10494        Sean Wright     6.5  219.0      361.0  Golden_State       99.6   \n",
       "10495          Ed Malloy     5.5  209.0      234.0  Golden_State       92.8   \n",
       "10496     James Williams     8.0  206.5      361.0  Golden_State       99.0   \n",
       "10497       Bill Kennedy     6.0  212.0      381.0  Golden_State      103.6   \n",
       "10498         Zach Zarba     9.5  216.0      534.0  Golden_State      106.9   \n",
       "...                  ...     ...    ...        ...           ...        ...   \n",
       "11723         John Goble    -4.5  197.0     -230.0     Milwaukee       94.0   \n",
       "11757     James Williams   -10.5  217.0    -1300.0     Minnesota       93.3   \n",
       "11758       Mark Lindsay   -10.0  214.0     -800.0     Minnesota       97.2   \n",
       "11759        Brian Forte   -11.5  219.0    -1200.0     Minnesota       91.0   \n",
       "11791       Mark Lindsay    -5.5  216.0     -240.0   New_Orleans       97.5   \n",
       "11792         John Goble    -6.0  212.5     -295.0   New_Orleans       95.5   \n",
       "11793       Bill Kennedy    -7.5  222.5     -330.0   New_Orleans      104.3   \n",
       "11794        Sean Wright   -10.5  227.0     -800.0   New_Orleans      110.2   \n",
       "11795         Josh Tiven   -12.0  229.0    -1095.0   New_Orleans      104.4   \n",
       "11894         Tony Brown     1.0  216.0      120.0  Philadelphia       98.7   \n",
       "11895        Kevin Scott     3.0  217.0      155.0  Philadelphia      107.8   \n",
       "11896    Derrick Collins     2.0  210.0      180.0  Philadelphia       96.1   \n",
       "11897         Tony Brown     3.5  207.0      144.0  Philadelphia       93.4   \n",
       "11898         Zach Zarba     1.5  204.5     -120.0  Philadelphia       98.1   \n",
       "11966     Jason Phillips    -3.0  216.0     -160.0      Portland      101.5   \n",
       "11967        Mark Ayotte    -6.0  216.0     -270.0      Portland      100.4   \n",
       "12032    Kane Fitzgerald    -8.0  210.0     -365.0   San_Antonio       96.6   \n",
       "12033      Brent Barnaky    -9.5  207.0     -530.0   San_Antonio       94.1   \n",
       "12034     Jason Phillips   -11.0  204.5    -1000.0   San_Antonio       93.6   \n",
       "12068     James Williams    -2.0  218.0     -115.0       Toronto       98.2   \n",
       "12069         Josh Tiven     0.0  218.5     -115.0       Toronto       98.9   \n",
       "12070       Bennie Adams    -1.0  215.0      115.0       Toronto       87.3   \n",
       "12071  Courtney Kirkland    -4.0  217.0     -190.0       Toronto       91.6   \n",
       "12072      David Guthrie    -5.5  213.0     -210.0       Toronto       93.2   \n",
       "12106  Courtney Kirkland   -10.0  205.0    -1100.0          Utah       96.8   \n",
       "12107        Rodney Mott   -11.5  206.0     -900.0          Utah      103.2   \n",
       "12108         Eric Lewis   -12.0  209.5    -1150.0          Utah       91.1   \n",
       "12142         Pat Fraher    -8.0  211.0     -380.0    Washington       98.1   \n",
       "12143  Courtney Kirkland    -7.0  215.0     -325.0    Washington      102.8   \n",
       "12144         John Goble    -7.0  214.5     -320.0    Washington       97.4   \n",
       "\n",
       "           ...      in_conference_game actual_y predicted_label_rf  \\\n",
       "10206      ...                       1        0                  0   \n",
       "10207      ...                       1        0                  1   \n",
       "10208      ...                       1        1                  1   \n",
       "10242      ...                       1        1                  1   \n",
       "10243      ...                       1        1                  1   \n",
       "10244      ...                       1        1                  1   \n",
       "10245      ...                       1        0                  0   \n",
       "10246      ...                       1        0                  0   \n",
       "10247      ...                       1        1                  0   \n",
       "10248      ...                       1        1                  1   \n",
       "10249      ...                       1        1                  1   \n",
       "10315      ...                       1        1                  1   \n",
       "10316      ...                       1        1                  1   \n",
       "10317      ...                       1        0                  1   \n",
       "10352      ...                       1        1                  1   \n",
       "10353      ...                       1        1                  1   \n",
       "10354      ...                       1        1                  1   \n",
       "10355      ...                       1        1                  1   \n",
       "10356      ...                       1        1                  1   \n",
       "10357      ...                       1        1                  1   \n",
       "10358      ...                       1        1                  1   \n",
       "10359      ...                       0        0                  1   \n",
       "10360      ...                       0        0                  1   \n",
       "10361      ...                       0        0                  0   \n",
       "10493      ...                       1        0                  1   \n",
       "10494      ...                       1        1                  1   \n",
       "10495      ...                       1        1                  1   \n",
       "10496      ...                       1        1                  1   \n",
       "10497      ...                       1        1                  1   \n",
       "10498      ...                       1        1                  1   \n",
       "...        ...                     ...      ...                ...   \n",
       "11723      ...                       1        0                  1   \n",
       "11757      ...                       1        1                  1   \n",
       "11758      ...                       1        0                  1   \n",
       "11759      ...                       1        0                  1   \n",
       "11791      ...                       1        1                  1   \n",
       "11792      ...                       1        1                  1   \n",
       "11793      ...                       1        0                  0   \n",
       "11794      ...                       1        1                  0   \n",
       "11795      ...                       1        1                  1   \n",
       "11894      ...                       1        1                  1   \n",
       "11895      ...                       1        1                  1   \n",
       "11896      ...                       1        0                  0   \n",
       "11897      ...                       1        0                  0   \n",
       "11898      ...                       1        0                  0   \n",
       "11966      ...                       1        0                  1   \n",
       "11967      ...                       1        0                  1   \n",
       "12032      ...                       1        0                  1   \n",
       "12033      ...                       1        0                  1   \n",
       "12034      ...                       1        1                  1   \n",
       "12068      ...                       1        0                  1   \n",
       "12069      ...                       1        0                  1   \n",
       "12070      ...                       1        1                  1   \n",
       "12071      ...                       1        1                  1   \n",
       "12072      ...                       1        0                  1   \n",
       "12106      ...                       1        0                  1   \n",
       "12107      ...                       1        1                  1   \n",
       "12108      ...                       1        1                  1   \n",
       "12142      ...                       1        0                  1   \n",
       "12143      ...                       1        0                  0   \n",
       "12144      ...                       1        0                  1   \n",
       "\n",
       "      predicted_proba_rfp predicted_label_svc predicted_proba_svcp  \\\n",
       "10206            0.494670                   1             0.508624   \n",
       "10207            0.515615                   1             0.514083   \n",
       "10208            0.515357                   1             0.553941   \n",
       "10242            0.528463                   1             0.546206   \n",
       "10243            0.521467                   0             0.500000   \n",
       "10244            0.524604                   1             0.518917   \n",
       "10245            0.464201                   0             0.449682   \n",
       "10246            0.472905                   0             0.479131   \n",
       "10247            0.494745                   0             0.472497   \n",
       "10248            0.514837                   0             0.484631   \n",
       "10249            0.565359                   0             0.500000   \n",
       "10315            0.500778                   1             0.532963   \n",
       "10316            0.505878                   0             0.500000   \n",
       "10317            0.520694                   0             0.500000   \n",
       "10352            0.545786                   1             0.554607   \n",
       "10353            0.574292                   1             0.550035   \n",
       "10354            0.533933                   1             0.538828   \n",
       "10355            0.562313                   1             0.554625   \n",
       "10356            0.542387                   1             0.546684   \n",
       "10357            0.523731                   1             0.531085   \n",
       "10358            0.535271                   1             0.510917   \n",
       "10359            0.547565                   1             0.562508   \n",
       "10360            0.547571                   1             0.523411   \n",
       "10361            0.497707                   0             0.494512   \n",
       "10493            0.531105                   1             0.517780   \n",
       "10494            0.502226                   1             0.507209   \n",
       "10495            0.532171                   1             0.506394   \n",
       "10496            0.542216                   1             0.509034   \n",
       "10497            0.540461                   1             0.541818   \n",
       "10498            0.514146                   1             0.511447   \n",
       "...                   ...                 ...                  ...   \n",
       "11723            0.521740                   1             0.520726   \n",
       "11757            0.540627                   1             0.555373   \n",
       "11758            0.518981                   1             0.514043   \n",
       "11759            0.541623                   1             0.524745   \n",
       "11791            0.510472                   0             0.500000   \n",
       "11792            0.535566                   0             0.469715   \n",
       "11793            0.494637                   0             0.478725   \n",
       "11794            0.485452                   0             0.468963   \n",
       "11795            0.507139                   0             0.467399   \n",
       "11894            0.510435                   0             0.465073   \n",
       "11895            0.521792                   0             0.492327   \n",
       "11896            0.491388                   1             0.512703   \n",
       "11897            0.469368                   0             0.478609   \n",
       "11898            0.458067                   0             0.464562   \n",
       "11966            0.533947                   1             0.540270   \n",
       "11967            0.550097                   1             0.557061   \n",
       "12032            0.570174                   1             0.546135   \n",
       "12033            0.501049                   1             0.526028   \n",
       "12034            0.524591                   1             0.541764   \n",
       "12068            0.504333                   0             0.492564   \n",
       "12069            0.526251                   0             0.493019   \n",
       "12070            0.500325                   0             0.492459   \n",
       "12071            0.511712                   1             0.533455   \n",
       "12072            0.538442                   1             0.519632   \n",
       "12106            0.529813                   1             0.524049   \n",
       "12107            0.508939                   1             0.508665   \n",
       "12108            0.526805                   1             0.536901   \n",
       "12142            0.541385                   1             0.521094   \n",
       "12143            0.499475                   0             0.472272   \n",
       "12144            0.501325                   0             0.484378   \n",
       "\n",
       "       predicted_label_lr  predicted_proba_lrp  vote  vote_with_rf  \n",
       "10206                   0             0.397912     1             1  \n",
       "10207                   0             0.384416     1             2  \n",
       "10208                   1             0.667802     2             3  \n",
       "10242                   1             0.596870     2             3  \n",
       "10243                   0             0.364219     0             1  \n",
       "10244                   1             0.471110     2             3  \n",
       "10245                   0             0.092167     0             0  \n",
       "10246                   0             0.173289     0             0  \n",
       "10247                   0             0.194460     0             0  \n",
       "10248                   0             0.305897     0             1  \n",
       "10249                   0             0.340284     0             1  \n",
       "10315                   1             0.582380     2             3  \n",
       "10316                   0             0.353033     0             1  \n",
       "10317                   0             0.427651     0             1  \n",
       "10352                   1             0.671290     2             3  \n",
       "10353                   1             0.634783     2             3  \n",
       "10354                   1             0.596524     2             3  \n",
       "10355                   1             0.736269     2             3  \n",
       "10356                   1             0.677631     2             3  \n",
       "10357                   1             0.583389     2             3  \n",
       "10358                   1             0.488018     2             3  \n",
       "10359                   1             0.759000     2             3  \n",
       "10360                   1             0.533924     2             3  \n",
       "10361                   0             0.318495     0             0  \n",
       "10493                   1             0.475317     2             3  \n",
       "10494                   0             0.336394     1             2  \n",
       "10495                   1             0.464295     2             3  \n",
       "10496                   1             0.463341     2             3  \n",
       "10497                   1             0.543570     2             3  \n",
       "10498                   0             0.392111     1             2  \n",
       "...                   ...                  ...   ...           ...  \n",
       "11723                   0             0.380716     1             2  \n",
       "11757                   1             0.781375     2             3  \n",
       "11758                   0             0.437741     1             2  \n",
       "11759                   0             0.418273     1             2  \n",
       "11791                   0             0.339848     0             1  \n",
       "11792                   0             0.161729     0             1  \n",
       "11793                   0             0.212550     0             0  \n",
       "11794                   0             0.124721     0             0  \n",
       "11795                   0             0.124603     0             1  \n",
       "11894                   0             0.119301     0             1  \n",
       "11895                   0             0.227360     0             1  \n",
       "11896                   0             0.368549     1             1  \n",
       "11897                   0             0.167640     0             0  \n",
       "11898                   0             0.138441     0             0  \n",
       "11966                   1             0.604200     2             3  \n",
       "11967                   1             0.683876     2             3  \n",
       "12032                   1             0.659992     2             3  \n",
       "12033                   1             0.474891     2             3  \n",
       "12034                   1             0.624887     2             3  \n",
       "12068                   0             0.303499     0             1  \n",
       "12069                   0             0.258052     0             1  \n",
       "12070                   0             0.287588     0             1  \n",
       "12071                   1             0.468304     2             3  \n",
       "12072                   0             0.361402     1             2  \n",
       "12106                   0             0.439323     1             2  \n",
       "12107                   0             0.365968     1             2  \n",
       "12108                   1             0.543055     2             3  \n",
       "12142                   0             0.384253     1             2  \n",
       "12143                   0             0.146835     0             0  \n",
       "12144                   0             0.162301     0             1  \n",
       "\n",
       "[150 rows x 182 columns]"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

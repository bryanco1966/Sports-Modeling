{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datatools import DataGrapher\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the data\n",
    "\n",
    "nba = pd.read_csv('./data/nba_analysis_data.csv')\n",
    "nba.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    " features = ['home_win_pct', 'away_win_pct',\n",
    "             'eff_ratio1','eff_ratio2',\n",
    "            'mov_5_fta', 'mov_5_away_fta',  \n",
    "             'eff_ratio3', 'eff_ratio4', \n",
    "            'mov_5_home_score', 'mov_5_away_score',\n",
    "            'mov_5_away_off_eff', 'mov_5_away_def_eff', \n",
    "            'mov_5_away_assists', 'mov_5_home_win_margin',\n",
    "            'mov_5_win', 'home_ave_win_margin', \n",
    "            'mov_5_away_win_margin', 'home_win_pct', 'away_win_pct',\n",
    "            'high_alt', 'home_ave_win_margin', 'away_ave_win_margin',\n",
    "            'playoff_game', 'mov_5_3pa', 'mov_5_away_3pa',\n",
    "            'mov_2_fta', 'mov_2_away_fta', \n",
    "           'mov_2_home_score', 'mov_2_away_score',\n",
    "           'mov_2_tot', 'mov_2_away_total_reb',\n",
    "           'mov_2_away_off_eff', 'mov_2_away_def_eff', \n",
    "            'mov_2_away_assists', 'mov_2_home_win_margin',\n",
    "           'mov_2_win', 'mov_2_away_win_margin', 'mov_2_3pa', \n",
    "            'mov_2_away_3pa','away_rest', 'rest_days'\n",
    "            ]\n",
    "X = nba.drop(columns = ['cover', 'home_win_margin', 'spread'])\n",
    "\n",
    "y = nba['cover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data for a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y ,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#scaling data to use in various other methods\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(n_components=18)\n",
    "X_train_pc = pc.fit_transform(X_train_scaled)\n",
    "X_test_pc = pc.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:             [0.20946555 0.17131883 0.16094599 0.11182761 0.05200998 0.0471987\n",
      " 0.04208947 0.03354746 0.0329927  0.03011603 0.02735211 0.0191045\n",
      " 0.01657406 0.0112369  0.01046281 0.00693507 0.00625639 0.00423406]\n",
      "Cumulative explained variance:  [0.20946555 0.38078438 0.54173037 0.65355797 0.70556795 0.75276665\n",
      " 0.79485612 0.82840359 0.86139629 0.89151232 0.91886442 0.93796892\n",
      " 0.95454298 0.96577989 0.97624269 0.98317777 0.98943416 0.99366822]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pc.explained_variance_ratio_\n",
    "print('Explained variance:            ', var_exp)\n",
    "\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative explained variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5235869723966701"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(penalty='l1', solver ='saga', cv =3 )\n",
    "lr.fit(X_train_pc, y_train)\n",
    "lr.score(X_train_pc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5238720981165134"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_pc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lr = lr.predict(X_train_pc)\n",
    "y_hat_lrp = lr.predict_proba(X_test_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      3585\n",
      "           1       0.00      0.00      0.00      3262\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6847\n",
      "   macro avg       0.26      0.50      0.34      6847\n",
      "weighted avg       0.27      0.52      0.36      6847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_hat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3585,    0],\n",
       "       [3262,    0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_train, y_hat_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Model seems to work best with bare bones information.  More information confused the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb_params = {\n",
    "    'var_smoothing' : [.3,.4 ] \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4957957999395462\n",
      "{'var_smoothing': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(nb, param_grid=nb_params, scoring='precision')\n",
    "gs.fit(X_train_pc, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5211726384364821"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_pc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_nb = gs.predict(X_test_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66      1196\n",
      "           1       0.52      0.15      0.23      1087\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      2283\n",
      "   macro avg       0.53      0.51      0.45      2283\n",
      "weighted avg       0.53      0.53      0.46      2283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[920, 276],\n",
       "       [804, 283]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

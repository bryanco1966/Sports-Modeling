{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the data\n",
    "\n",
    "nba = pd.read_csv('./data/nba_analysis_data.csv')\n",
    "nba.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " features = ['home_win_pct', 'away_win_pct',\n",
    "             'eff_ratio1','eff_ratio2',\n",
    "            'mov_5_fta', 'mov_5_away_fta',  \n",
    "             'eff_ratio3', 'eff_ratio4', \n",
    "            'mov_5_home_score', 'mov_5_away_score',\n",
    "            'mov_5_away_off_eff', 'mov_5_away_def_eff', \n",
    "            'mov_5_away_assists', 'mov_5_home_win_margin',\n",
    "            'mov_5_win', 'home_ave_win_margin', \n",
    "            'mov_5_away_win_margin', 'home_win_pct', 'away_win_pct',\n",
    "            'high_alt', 'home_ave_win_margin', 'away_ave_win_margin',\n",
    "            'playoff_game', 'mov_5_3pa', 'mov_5_away_3pa',\n",
    "            'mov_2_fta', 'mov_2_away_fta', \n",
    "           'mov_2_home_score', 'mov_2_away_score',\n",
    "           'mov_2_tot', 'mov_2_away_total_reb',\n",
    "           'mov_2_away_off_eff', 'mov_2_away_def_eff', \n",
    "            'mov_2_away_assists', 'mov_2_home_win_margin',\n",
    "           'mov_2_win', 'mov_2_away_win_margin', 'mov_2_3pa', \n",
    "            'mov_2_away_3pa','away_rest', 'rest_days'\n",
    "            ]\n",
    "X = nba.drop(columns = ['cover', 'home_win_margin'])\n",
    "\n",
    "y = nba['cover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data for a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y ,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#scaling data to use in various other methods\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/bryancombs/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5300131444428217"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(penalty='l1', solver ='saga', cv =3 )\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212439772229522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lr = lr.predict(X_test_scaled)\n",
    "y_hat_lrp = lr.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.64      1196\n",
      "           1       0.49      0.18      0.27      1087\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      2283\n",
      "   macro avg       0.51      0.51      0.46      2283\n",
      "weighted avg       0.51      0.52      0.46      2283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[991, 205],\n",
       "       [888, 199]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Model seems to work best with bare bones information.  More information confused the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5282605520665985\n",
      "0.5260621988611476\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing=4)\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "print(nb.score(X_train_scaled, y_train))\n",
    "print(nb.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_nb = nb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68      1196\n",
      "           1       0.52      0.06      0.11      1087\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      2283\n",
      "   macro avg       0.52      0.50      0.39      2283\n",
      "weighted avg       0.52      0.53      0.41      2283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1133,   63],\n",
       "       [1019,   68]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix( y_test, y_hat_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
